---
title: "Ejercicio 2"
topic: "General"
number: "2"
originalUrl: "exports/downloads/Todos los ramos/Pauta Interrogación 1_1W6SMWrwUpzWhoCitM2t.pdf"
sourceFile: "Pauta Interrogación 1_1W6SMWrwUpzWhoCitM2t.pdf"
---

(15 puntos)  2.1   (5 puntos) Enuncie el teorema de Gauss-Markov ¿Qu´ e implica este teorema? El teorema de Gauss Markov menciona que si en un modelo se cumple (1) linealidad, (2) rango completo, (3) exogeneidad estricta y (4) errores esf´ ericos, entonces el estimador MCO es eficiente respecto a la clase de estimadores lineales insesgados. El teorema implica que el estimador MCO es insesgado, es decir, su esperanza corresponde al coeficiente, adem´ as que tiene varianza m´ ınima entre todos los dem´ as estimadores lineales insesgados, luego es el m´ as eficiente en el sentido del error cuadr´ atico medio. En estad´ ıstica, aquellos estimadores son los m´ as codiciados, ya que generan intervalos de confianza, asumiendo un buen tratamiento de datos, con largo te´ oricamente peque˜ no.  (1.5 puntos)   Por mencionar que el estimador MCO es insesgado.  (1.5 puntos)   Por mencionar que el estimador MCO es eficiente (o de varianza m´ ınima) en la clase de estimadores lineales insesgados. Puntaje parcial (1 punto) si no se menciona que es en la clase de estimadores lineales insesgados.  (2 puntos)   Por explicar la implicancia estad´ ıstica del teorema.  2.2   (10 puntos) Demuestre cu´ al es el sesgo cuando hay un error en la medici´ on en uno de los   X   y cuando hay error de medici´ on en   Y   . Explicite sus supuestos de ser necesario. Para mostrar el sesgo podemos utilizar una regresi´ on simple del tipo:   y i   =   α   +   βx i   +   μ i .   Al incorporar un error de medici´ on en   x i , del tipo   x ′  i   =   x i   +   s i , con   s i   un error aleatorio en la medici´ on, tenemos que el coeficiente   β   puede ser estimado, incorrectamente, seg´ un:  b   =  Cov( x ′ , y ) Var( x ′ ) =  Cov( x   +   s, α   +   xβ   +   μ i ) Var( x   +   s ) =   β   Var( x ) Var( x ) + Var( s )   (2) donde   x   = ( x 1 , x 2 , ..., x n ) ′ ,   s   = ( s 1 , s 2 , ..., s n ) ′   y   y   = ( y 1 , y 2 , ..., y n ).   Luego, si   s i   y   μ i   son independientes, existe efectivamente un sesgo en la estimaci´ on del coeficiente. Por otro lado, si queremos estimar una regresi´ on del tipo   y i   =   α   +   βx i   +   μ i , pero medimos incorrectamente la variable dependiente seg´ un   y ′  i   =   y i   +   s i , entonces el coeficiente estimado:  b   =  Cov( y ′ , x ) Var( x ) =  Cov( y   +   s ) Var( x ) =  Cov( α   +   xβ   +   μ   +   s ) Var( x ) =   β   Var( x ) Var( x ) =   β   (3) donde   x   = ( x 1 , x 2 , ..., x n ) ′ ,   s   = ( s 1 , s 2 , ..., s n ) ′   y   y   = ( y 1 , y 2 , ..., y n ). Todo lo anterior, es asumiendo que   x i   y  s i , μ i   son variables independientes entre s´ ı. Luego no existe un sesgo en la estimaci´ on de   β , pero tendr´ ıamos una regresi´ on del tipo   y i   =   α   +   βx i   +   μ i   +   s i , es decir, el error tendr´ ıa un t´ ermino adicional.   Esto puede reducir la potencia del test de significancia. 3

--- Page 4 ---
(3 puntos)   Por obtener correctamente el sesgo al incluir un error en la medida de   x , seg´ un (2)  (2 puntos)   Por explicitar claramente que   s i   y   μ i   son independientes.  (3 puntos)   Por obtener correctamente que no existe un sesgo en la medici´ on del coeficiente al incluir un error en la medida de   y , seg´ un (3)  (2 puntos)   Por explicitar claramente que   x i   y   s i , μ i   son variables independientes entre s´ ı. 4

--- Page 5 ---