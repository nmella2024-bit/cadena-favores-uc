---
title: "Ejercicio 1"
topic: "General"
number: "1"
originalUrl: "exports/downloads/Todos los ramos/Examen 2018-1_3HEqhI4bZGmr3THXgSd8.pdf"
sourceFile: "Examen 2018-1_3HEqhI4bZGmr3THXgSd8.pdf"
---

(16 puntos):  Responda brevemente las siguientes preguntas, sobre la base de los contenidos del curso (Note las diferencias de puntaje de las partes).  a) (2 pts)   Considere el problema no restringido min x ∈ R n   f   ( x ), donde   f   es una funci´ on convexa 2 veces continuamente diferenciable de   n   variables. Queremos encontrar una soluci´ on aproximada y para eso usamos el m´ etodo de Newton. Suponga que se ejecutan   k   iteraciones del m´ etodo a partir de un punto inicial   x 0 . Suponiendo que las evaluaciones de   ∇ f   ( x ) y   ∇ 2 f   ( x ) requieren en total   O ( n 2 ) operaciones aritm´ eticas, ¿cu´ al es el orden del n´ umero de operaciones aritm´ eticas totales realizadas en cada iteraci´ on del m´ etodo? Justifique con precisi´ on su respuesta.  Respuesta:   Adem´ as de evaluar los gradientes y Hessiano, Newton requiere calcular la direcci´ on de avance y eso es   O ( n 3 ) ya que implica calcular   ∇ 2 f   ( x ) − 1 , o resolver un sistema de ecuaciones con esa matriz. Luego, es   O ( n 3 ) por iteraci´ on y eso da un total de   O ( kn 3 ).  b) (4 pts)   Considere el problema restringido en   R n : min   f   ( x )  s.a.   x   ∈   S,  donde   f   es una funci´ on fuertemente convexa, diferenciable y   S   es un conjunto convexo cerrado y aco- tado.   Se quiere resolver el problema con un m´ etodo de primer orden y se va a usar el m´ etodo del gradiente a partir de un punto   x 0 . Escriba la expresi´ on (f´ ormula) que define la iteraci´ on general del m´ etodo para este problema, asumiendo un paso fijo igual a   α   (no hay “linesearch”).  Respuesta:   La iteraci´ on es  x k +1   =   P roy S   ( x k   −   α ∇ f   ( x k )) donde   P roy S   es la proyecci´ on euclideana sobr el conjunto   S . Tiene que hacerse la proyecci´ on, de otro modo no hay garant´ ıa de factibilidad de las iteraciones. Nota de correcci´ on: 1 punto por ponerlo sin proyecci´ on.  c) (4 pts)   Explique brevemente por qu´ e el An´ alisis de Sensibilidad tradicional de Programaci´ on Lineal no es necesariamente un buen enfoque para abordar problemas de incertidumbre en un modelo de opti- mizaci´ on lineal.  Respuesta:   Por que es un an´ alisis limitado al ser s´ olo local dentro de l´ ımites eventualmente chicos y, adem´ as, es “a pasdteriori”, se hace cuando ya est´ a calculada una soluci´ on sobre la base de valores de par´ ametros ya asumidos.  d) (2 pts)   Considere el siguiente problema de optimizaci´ on lineal “binario”:  z ∗   = min   c T   x s.a.   Ax   =   b x j   ∈ { 0 ,   1 } , j   = 1 , . . . , n  donde   A   es de   m   ×   n ,   b   ∈   R m ,   c   ∈   R n . Si se escribe el dual lagrangeano de este problema y el valor ´ optimo de ese dual es igual a   w ∗ , ¿son iguales o no   w ∗   con   z ∗ ? Justifique con toda precisi´ on su respuesta.

--- Page 2 ---
Respuesta:   En general se tendr´ a que no ya que, debido a que un problema de optimizaci´ on entera NO es convexo, no habr´ a dualidad fuerte.  e) (4 pts)   En forma muy breve explique a qu´ e tipo de estructura de problema se aplican los siguientes enfoques de optimizaci´ on de gran escala: i) Generaci´ on de Columnas, ii) Descomposici´ on de Dantzig- Wolfe, ii) Descomposici´ on de Benders (puede usar, tambi´ en, diagramas para su explicaci´ on).  Respuesta:  Generaci´ on de columnas se aplica a un problema que tiene muchas m´ as columnas que restricciones. Dantzig -Wolfe se aplica a una estructura de bloques independientes m´ as uno com´ un (ac´ a puede hacerse el dibujo mostrado en clases), y Benders se aplica a estructuras con “variables complicantes” de la forma min   c T   x   +   d T   y s.a.   Ax   =   b Ex   +   Dy   =   e x   ∈   C   y   ≥   0 (tambi´ en puede ir un dibujo de los bloques).